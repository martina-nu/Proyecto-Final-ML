{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 0. Load libraries and custom modules\n",
    "# Dataframes and matrices ----------------------------------------------\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "# Graphics -------------------------------------------------------------\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from matplotlib import style\n",
    "plt.style.use('tableau-colorblind10')\n",
    "# Mathematical functions -----------------------------------------------\n",
    "from scipy.stats import norm\n",
    "# Text processors ------------------------------------------------------\n",
    "import unicodedata\n",
    "import re\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from wordcloud import WordCloud\n",
    "# Preprocessing --------------------------------------------------------\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "# Text modeling --------------------------------------------------------\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "# Model creating -------------------------------------------------------\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "# Metrics --------------------------------------------------------------\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import plot_roc_curve\n",
    "from sklearn.metrics import ConfusionMatrixDisplay\n",
    "from sklearn.metrics import make_scorer\n",
    "# Custom functions -----------------------------------------------------\n",
    "from text_preprocessing import clean_stopwords "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We'll use a collection of sentiments for text analysis as a dataset\n",
    "# This dataset was published in Saif M. Mohammad and Peter Turney. (2013), \n",
    "# ``Crowdsourcing a Word-Emotion Association Lexicon.'' \n",
    "# Computational Intelligence, 29(3): 436-465.\n",
    "# It's only for research and educational purposes.\n",
    "# URL: http://saifmohammad.com/WebPages/lexicons.html  \n",
    "nrc = pd.read_csv('data/raw/NRC.csv', names=['word','sentiment','polarity'])\n",
    "nrc = nrc.query('polarity == 1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1. Load the data\n",
    "# Data extracted from https://www.thetrumparchive.com\n",
    "# Data case: During the 2016 US presidential election, the candidate \n",
    "# Donald Trump used twitter to communicate with potential voters. \n",
    "# The campaign was during 2015-06-17 and 2016-11-08\n",
    "# We'll try to analyze these campaign tweets from iPhone and Android\n",
    "# Data description\n",
    "# source -> device of origin\n",
    "# id_str -> unique identifier\n",
    "# text -> tweet text content\n",
    "# created_at -> Date of creation, not including timezone\n",
    "# retweet_count -> Count of retweets (difusion)\n",
    "# in_reply_to_usr_id_str -> If it's a reply, grab the user id\n",
    "# favourite_count -> Count of users that liked the tweet\n",
    "# is_retweet -> If the post is a retweet  \n",
    "# 1.1 Open data and get a glimpse\n",
    "df_raw = pd.read_csv('data/raw/trump_tweets.csv')\n",
    "df_raw.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1.1 Sample some observations\n",
    "df_raw.sample(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 2. Transform and wrangle the data\n",
    "# 2.1 Make a copy\n",
    "df_interim = df_raw.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2.2 Get rid of uninformative columns\n",
    "df_interim = df_interim.drop(['id_str','is_retweet','in_reply_to_user_id_str'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2.3 Convert columns to the right format\n",
    "df_interim['created_at'] = df_interim['created_at'].astype('datetime64')\n",
    "df_interim['source'] = pd.Categorical(df_interim['source'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2.4 Filter dates for analysis\n",
    "df_interim = df_interim.loc[(df_interim['created_at'] >= '2015-06-17') \\\n",
    "    & (df_interim['created_at'] <= '2016-11-08')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2.5 Consider time is UTC, convert to EST\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2.5 Filter source for analysis\n",
    "df_interim = df_interim.loc[(df_interim['source'].str.contains('iPhone')) \\\n",
    "    | (df_interim['source'].str.contains('Android'))]\n",
    "df_interim['source'] = df_interim['source'].cat.remove_unused_categories()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2.5 Save and create a copy for analysis\n",
    "df_interim.to_csv('data/interim/trump_tweets.csv', index=False)\n",
    "df = df_interim.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 3. Perform EDA\n",
    "# 3.1 Get basic info\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3.2 Get a sample\n",
    "df.sample(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3.3 Describe numerical and datetime data\n",
    "df.describe(datetime_is_numeric=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3.4 Describe categorical data\n",
    "df['source'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3.5 Get histograms for numerical data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3.6 Make a plot of tweets frequence rate by source"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3.7 Get a glimpse of the most retweeted tweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3.8 Get a glimpse of the most liked tweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3.9 Let's get a glimpse of common words in the tweets' text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3.10 Process text to extract stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3.11 Extract urls\n",
    "url_pat = 'https://t.co/[A-Za-z\\d]+|&amp;'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3.12 Extract special characters\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3.13 Extract numbers\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3.14 See the results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3.15 Let's see a wordcloud\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.10 ('Commons')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "bc7f7a2d7b5a13e1df9879b693cf35a001b0abe7ad7fabfa2efe5a3b8907473a"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
